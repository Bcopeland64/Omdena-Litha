{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QZQsxGWbNyT4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUJx0scSQy4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53628b89-f577-4ce7-bb7e-380678d2434f"
      },
      "source": [
        "# Setup\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1pSMEZd7VH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7325434b-7694-4084-d81c-1a1ca91e5f1b"
      },
      "source": [
        "from nltk.parse.stanford import StanfordDependencyParser\n",
        "!pip install stanfordcorenlp\n",
        "!pip install parse"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stanfordcorenlp in /usr/local/lib/python3.7/dist-packages (3.9.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp) (5.4.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (1.19.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ling_images = pd.read_json('/content/image_dictionary.json')"
      ],
      "metadata": {
        "id": "KoGnu_lhOF_6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ling_images.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OO68igmLO1GS",
        "outputId": "8dbb2688-547f-42af-d64f-101cd007e2dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           ImageDictionary\n",
              "0                          an A for effort\n",
              "1  A man's gotta do what a man's gotta do.\n",
              "2     Abandon hope, all ye who enter here.\n",
              "3            abandon oneself to something.\n",
              "4                            abandon ship."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b78e53e1-41a4-4ce8-bcca-0a8f8bd516ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageDictionary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>an A for effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A man's gotta do what a man's gotta do.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abandon hope, all ye who enter here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abandon oneself to something.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abandon ship.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b78e53e1-41a4-4ce8-bcca-0a8f8bd516ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b78e53e1-41a4-4ce8-bcca-0a8f8bd516ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b78e53e1-41a4-4ce8-bcca-0a8f8bd516ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dct7Q7jjfmjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "628fbe73-535a-42b0-848e-ca3d0a29b5dc"
      },
      "source": [
        "import re\n",
        "from parse import parse\n",
        "\n",
        "def dependency_parse(sentence):\n",
        "    \"\"\" Accepts a sentence and returns its dependency parse as a list-of-lists\n",
        "    Also returns the list of nouns in the sentence\n",
        "    \"\"\"\n",
        "\n",
        "    # sentence =input(\"Enter a sentence: \")\n",
        "\n",
        "    parser_folder = \"parser\"    # Change if parser is in some other directory\n",
        "    parse_output = parse(sentence, parser_folder)\n",
        "\n",
        "    # List of nouns\n",
        "    const_parse = str(ling_images)\n",
        "    print(const_parse)\n",
        "    regex_pattern = r\"\\(NN (\\w+)\\)\"\n",
        "    NN_list = re.findall(r\"\\(NN (\\w+)\\)\", const_parse)\n",
        "    NNS_list = re.findall(r\"\\(NNS (\\w+)\\)\", const_parse)\n",
        "\n",
        "    noun_list = sorted(NN_list + NNS_list)\n",
        "\n",
        "    # Dependency parse\n",
        "    dep_parse = parse_output[0].split(\"\\n\")\n",
        "\n",
        "    print (\"---\")\n",
        "    dependency_parse=[]\n",
        "    for i in dep_parse:\n",
        "        if len(i.strip()) > 0 and i.strip()[0] != \"(\":\n",
        "            line=i.strip()\n",
        "            dependency_parse.append(filter(lambda x:x.isalpha(),re.findall(r\"[\\w']+\", line)))\n",
        "\n",
        "    return dependency_parse, noun_list\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sentence =input(\"Enter a sentence: \")\n",
        "\n",
        "    print(dependency_parse(sentence))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: an A for effort\n",
            "                               ImageDictionary\n",
            "0                              an A for effort\n",
            "1      A man's gotta do what a man's gotta do.\n",
            "2         Abandon hope, all ye who enter here.\n",
            "3                abandon oneself to something.\n",
            "4                                abandon ship.\n",
            "...                                        ...\n",
            "19016           zoom past someone or something\n",
            "19017               zoom someone or something \n",
            "19018                   zoom through something\n",
            "19019                                 zoom up \n",
            "19020                              zounked out\n",
            "\n",
            "[19021 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1a852bf43e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a sentence: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependency_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-1a852bf43e55>\u001b[0m in \u001b[0;36mdependency_parse\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Dependency parse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdep_parse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoXdrEYTSQKH"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FngzXpW2TJs6"
      },
      "source": [
        "from setuptools import setup\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUBY1nURSaDX"
      },
      "source": [
        "def detect_metaphor(sentence):\n",
        "   dep_parse_output, noun_list = dependency_parse((sentence.lower())\n",
        "   nsubj_pairs = [ns_parse[1:] for ns_parse in filter(lambda dp: dp[0] == \"nsubj\" and dp[1] in noun_list and dp[2] in noun_list, dep_parse_output)]\n",
        "   for pair in nsubj_pairs:\n",
        "       print (\"\\nInvestigating metaphor for pair {0}\".format(pair))\n",
        "\n",
        "       syn_pair = []\n",
        "       for word in pair:\n",
        "\n",
        "             synsets = wn.synsets(word)\n",
        "             print (\"What sense of '{0}' would you like to use?\".format(word))\n",
        "             for i, synset in enumerate(synsets):\n",
        "                 print (\"{0}: {1}\".format(i, synset.definition))\n",
        "             chosen_id = int(raw_input(\"Enter number corresponding to sense: \"))\n",
        " \n",
        "             syn_pair.append(synsets[chosen_id])\n",
        "       \n",
        "       similarity_measure = similarity(syn_pair[0], syn_pair[1])\n",
        "       \n",
        "       if similarity_measure is None or similarity_measure >= 0.1:\n",
        "            print (\"{0} does NOT constitute a Noun-Noun metaphor, similarity {1}\".format(pair, similarity_measure))\n",
        "       else:\n",
        "            print (\"{0} constitutes a Noun-Noun metaphor, similarity {1}\".format(pair, similarity_measure))\n",
        "\n",
        "   if len(nsubj_pairs) == 0:\n",
        "        print (\"No Noun-Noun pairs detected. Thus the sentence is not a Noun-Noun metaphor\")\n",
        "      \n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz_cPYfOdMVm"
      },
      "source": [
        "def similarity(synset1, synset2):\n",
        "    \"\"\" Accepts 2 synsets and returns the similarity\n",
        "    \"\"\"\n",
        "\n",
        "    return synset1.path_similarity(synset2)\n",
        "if __name__ == \"__main__\":\n",
        "    sentence =input(\"Enter a sentence: \")\n",
        "\n",
        "    detect_metaphor(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZageil4XtZL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYn0Rn_QSxmf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}