{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA6MMbYDd4sO",
        "outputId": "e2a8caf5-a513-4646-f6fe-577c3497fe1d"
      },
      "id": "GA6MMbYDd4sO",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5d8e2464-93d3-4af7-a282-c802685f866e",
      "metadata": {
        "id": "5d8e2464-93d3-4af7-a282-c802685f866e"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")   # effeciency, works great for this project\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6e40555e-cb89-4db1-8ba0-35bc6e8c6d4e",
      "metadata": {
        "id": "6e40555e-cb89-4db1-8ba0-35bc6e8c6d4e"
      },
      "outputs": [],
      "source": [
        "def get_question(sentence, answer):\n",
        "    \"\"\"\n",
        "    generates question for the sentence based on a given answer\n",
        "    \"\"\"\n",
        "\n",
        "    mdl = T5ForConditionalGeneration.from_pretrained('mrm8488/t5-base-finetuned-question-generation-ap')\n",
        "    tknizer = AutoTokenizer.from_pretrained('mrm8488/t5-base-finetuned-question-generation-ap')\n",
        "\n",
        "    text = \"context: {} answer: {}\".format(sentence, answer)\n",
        "    max_len = 256\n",
        "    encoding = tknizer.encode_plus(text,\n",
        "                                   max_length=max_len, \n",
        "                                   pad_to_max_length=False,\n",
        "                                   truncation=True, \n",
        "                                   return_tensors=\"pt\")\n",
        "\n",
        "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "    outs = mdl.generate(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        early_stopping=True,\n",
        "                        num_beams=5,\n",
        "                        num_return_sequences=1,\n",
        "                        no_repeat_ngram_size=2,\n",
        "                        max_length=300)\n",
        "\n",
        "    dec = [tknizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "    Question = dec[0].replace(\"question:\",\"\")\n",
        "    Question = Question.strip()\n",
        "    Question = re.sub(r\"I am\", \"you are\", Question)\n",
        "    Question = re.sub(r\"I\", \"you\", Question)\n",
        "    Question = re.sub(r\"my\", \"your\", Question)\n",
        "    \n",
        "    return Question"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98660556-8d98-4dc8-8f6d-745355225ab1",
      "metadata": {
        "id": "98660556-8d98-4dc8-8f6d-745355225ab1"
      },
      "source": [
        "> <span style=\"color:LightSalmon\"> <span style='font-family:sans-serif'> <span style=\"font-size: 18px\"> First Pass: let's provide no answer, and let the model come up with its own question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5cb226b1-4ca6-40f3-bf5b-e6a304228655",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5cb226b1-4ca6-40f3-bf5b-e6a304228655",
        "outputId": "9887a3bb-45d3-4aa5-9415-06c2cd50d880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What kind of cloud do you feel like you are living under?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# ADJ is present before noun\n",
        "sentence = \"I feel like I am living under a dark, heavy cloud!!!\"\n",
        "get_question(sentence, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a7a7599b-47c5-4393-b58a-4822cf54c74b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "a7a7599b-47c5-4393-b58a-4822cf54c74b",
        "outputId": "0f7bd1a1-6024-4d70-bd0a-3e332b47c747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How do you hack your way through a forest?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# ADJ is present, but not before the word \"forest\" or \"way\"; the ADJ's are in the next sentences\n",
        "sentence = \"I am trying to hack my way through a forest; the way is unclear, and the forest is dense.\"\n",
        "get_question(sentence, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f5e2b01-eb6b-45f8-98bb-71cd5e6e20a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "1f5e2b01-eb6b-45f8-98bb-71cd5e6e20a7",
        "outputId": "eef23a53-3b69-4f03-f832-6b602721fcd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the feeling of living under a dark cloud?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# two metaphors\n",
        "sentence = \"I am trying to hack my way through a dense forest, and also feel like I am living under a dark cloud!\"\n",
        "get_question(sentence, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9b2b698-9c22-4ea4-9bad-f0e61137eeb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "b9b2b698-9c22-4ea4-9bad-f0e61137eeb1",
        "outputId": "338634ae-b118-4e89-d4b8-71566b1dc125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How do you hack your way through a forest?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# No ADJ\n",
        "sentence = \"I am trying to hack my way through a forest\"\n",
        "get_question(sentence, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3af8c6fc-ad23-4445-9ef4-6fd49652a7e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "3af8c6fc-ad23-4445-9ef4-6fd49652a7e6",
        "outputId": "93506acf-e1ec-4196-c0e3-4c784b247105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What felt like a dagger?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# No ADJ\n",
        "sentence = \"in my heart, that felt like a dagger\"\n",
        "get_question(sentence, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c0386428-8cb1-4893-8446-1e285df82e44",
      "metadata": {
        "id": "c0386428-8cb1-4893-8446-1e285df82e44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "87df118a-a03a-4290-bfa3-0cc87b512a59",
      "metadata": {
        "id": "87df118a-a03a-4290-bfa3-0cc87b512a59"
      },
      "source": [
        "> <span style=\"color:LightSalmon\"> <span style='font-family:sans-serif'> <span style=\"font-size: 18px\"> these `t5` generated questions look pretty good!\n",
        "\n",
        "> <span style=\"color:LightSalmon\"> <span style='font-family:sans-serif'> <span style=\"font-size: 18px\">we can also try to come up with an \"answer\" for model input:\n",
        "\n",
        ">> <span style=\"color:LightSalmon\"> <span style='font-family:sans-serif'> <span style=\"font-size: 16px\"> After testing different parts of speech for our answer, I found that if we target the ADJ in the utterance as the answer, the model generates questions that are very similar to clean-language questions. So, picking ADJ's is going to be our first way of providing an answer for the model.\n",
        "    \n",
        ">> <span style=\"color:LightSalmon\"> <span style='font-family:sans-serif'> <span style=\"font-size: 16px\"> If there is no ADJ, we can use \"pobj\" (object of a preposition) as the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4acc43b3-64d4-4960-a26f-b969ca79a837",
      "metadata": {
        "id": "4acc43b3-64d4-4960-a26f-b969ca79a837"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7905eaf9-1299-4e4c-b351-80ed15805a5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7905eaf9-1299-4e4c-b351-80ed15805a5a",
        "outputId": "78e2b66c-7449-41ad-c8aa-eb680c0de570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What kind of cloud do you feel like you are living under?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sentence = \"I feel like I am living under a dark, heavy cloud!!!\"\n",
        "answer = \"dark\"   # ADJ\n",
        "\n",
        "get_question(sentence, answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "44685910-cfad-463b-a6e9-9aaec00c57cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "44685910-cfad-463b-a6e9-9aaec00c57cc",
        "outputId": "06bd72d6-3459-4306-ee9f-6806deeed4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How dense is the forest?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sentence = \"I am trying to hack my way through a dense forest\"\n",
        "answer = \"dense\"   # ADJ\n",
        "\n",
        "get_question(sentence, answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "03dd4f54-7400-48f8-b1bb-fa05ee3d959b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "03dd4f54-7400-48f8-b1bb-fa05ee3d959b",
        "outputId": "0487c6b6-9f9d-4a99-f019-4e016575c38d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you are trying to hack your way through a what?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "sentence = \"I am trying to hack my way through a forest\"\n",
        "answer = \"forest\"   # POBJ\n",
        "\n",
        "get_question(sentence, answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bd70f780-d418-4dc1-9a10-391fdce91e38",
      "metadata": {
        "id": "bd70f780-d418-4dc1-9a10-391fdce91e38"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "97b7567f-ffe2-40d6-88ef-4f95827df419",
      "metadata": {
        "id": "97b7567f-ffe2-40d6-88ef-4f95827df419"
      },
      "source": [
        "> <span style=\"color:LightSalmon\"> <span style='font-family:sans-serif'> <span style=\"font-size: 18px\"> We can see that the last question is not quite what we want as a clean-language question; so, I did some basic text tweaking for when POBJ is going to be the answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a949380f-b921-4226-936c-91bf94d868d6",
      "metadata": {
        "id": "a949380f-b921-4226-936c-91bf94d868d6"
      },
      "outputs": [],
      "source": [
        "# custom fn: get OBJ from text as a list\n",
        "def extract_obj(text):\n",
        "    doc = nlp(text)\n",
        "    obj=[]\n",
        "    \n",
        "    for token in doc:\n",
        "        if re.findall(r'obj', token.dep_) == ['obj']:  # if token dependency has 'obj' in it --> dobj (direct object), pobj (object of a preposition)\n",
        "            obj.append(token.text)\n",
        "     \n",
        "    return list(set(obj))   # set for getting unique obj's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0ff9e7ab-66be-4481-9c94-dd0529481a94",
      "metadata": {
        "id": "0ff9e7ab-66be-4481-9c94-dd0529481a94"
      },
      "outputs": [],
      "source": [
        "# custom fn: get ADJ from text as alist\n",
        "def extract_adj(text):\n",
        "    doc = nlp(text)\n",
        "    adj=[]\n",
        "    \n",
        "    for token in doc:\n",
        "        if token.pos_ == 'ADJ':\n",
        "            adj.append(token.text)\n",
        "     \n",
        "    return list(set(adj))   # set for getting unique obj's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ab679fc2-304e-4587-9edc-ab0af3ac52a8",
      "metadata": {
        "id": "ab679fc2-304e-4587-9edc-ab0af3ac52a8"
      },
      "outputs": [],
      "source": [
        "def get_question_full():\n",
        "    if len(extract_adj(sentence)) == 0:           # if no ADJ\n",
        "        answer = extract_obj(sentence)\n",
        "        answer = \" and the \".join(answer[:2])     # for now, if more than one pobj exists in the utterance, we only get the first two pobj's\n",
        "        print(f'Can you describe/tell me more about the {answer}?')   \n",
        "    else:\n",
        "        answer = extract_adj(sentence)\n",
        "        answer = \" and \".join(answer[:1])          # for now, if more than one adj, we only get the first one\n",
        "        print(get_question(sentence, answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "830fddc7-9541-4dfc-a2fe-df24550f75f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "830fddc7-9541-4dfc-a2fe-df24550f75f6",
        "outputId": "b999a333-1244-497b-abbb-7e6125e8aaaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you describe/tell me more about the way and the forest?\n"
          ]
        }
      ],
      "source": [
        "sentence = \"I am trying to hack my way through a forest\"\n",
        "get_question_full()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e8e7fc78-4e88-4056-87be-83548f8ee9fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8e7fc78-4e88-4056-87be-83548f8ee9fc",
        "outputId": "cdee44ac-1010-4a49-e62a-80128750824e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you describe/tell me more about the heart and the dagger?\n"
          ]
        }
      ],
      "source": [
        "sentence = \"in my heart, that felt like a dagger\"\n",
        "get_question_full()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "815884d6-0560-4621-8b32-f5f521a04fd4",
      "metadata": {
        "id": "815884d6-0560-4621-8b32-f5f521a04fd4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env_nlp",
      "language": "python",
      "name": "env_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}